<div align="center">

# ðŸ’“ PulsePod
### A Robust Framework for Arrhythmia Detection using Deep and Spiking Neural Networks
**Deep Learning â€¢ Neuromorphic Computing â€¢ Real-Time Deployment**

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.8-EE4C2C?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![SNNTorch](https://img.shields.io/badge/SNN-Neuromorphic-darkblue)](https://snntorch.readthedocs.io/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?logo=streamlit&logoColor=red)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)]()

<p align="center">
  <a href="#-project-overview">Overview</a> â€¢
  <a href="#-technical-specifications">Tech Specs</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-installation">Installation</a> â€¢
  <a href="#-performance--results">Results</a>
</p>
</div>

---

## ðŸ©º Project Overview
**PulsePod** is an end-to-end AI system designed to detect cardiac abnormalities from ECG signals with high reliability and efficiency. Unlike traditional models that fail when deployed on new patient populations (the **Dataset Shift** problem), PulsePod is built for **generalization**.

![PulsePod Dashboard Demo](assets/dashboard.gif)

By training on a massive, unified dataset combining **MIT-BIH** and **PTB-XL** records , the system achieves robust performance across diverse demographics. It features a suite of models ranging from high-accuracy **1D-CNNs** to ultra-low-power **Spiking Neural Networks (SNNs)** designed for battery-constrained wearable devices

### ðŸŒŸ Key Features
* **ðŸ›¡ï¸ Robust Generalization:** Achieved **87% Accuracy** on the held-out **Unified Test Set** (61,126 samples), successfully generalizing across diverse signal sources.
* **ðŸ§  Neuromorphic Intelligence:** Validated **SNNs** (Leaky Integrate-and-Fire) achieving **85% accuracy** on the unified dataset, demonstrating viability for energy-efficient edge hardware.
* **âš–ï¸ Stratified Training:** Models trained on **244,502 heartbeats** with balanced class distribution to prevent bias and overfitting.
* **ðŸš€ Real-Time Dashboard:** Interactive Streamlit interface for visualizing live ECG inference and probability confidence.
---

## ðŸ”¬ Technical Specifications

The system was engineered and validated using rigorous quantitative benchmarks.

### ðŸ“Š Data Composition
* **Total Processed Heartbeats:** 305,628 (Train + Test)
* **Source Integration:**
    * **MIT-BIH:** 54,680 beats (Gold-standard arrhythmia annotations)
    * **PTB-XL:** 250,948 beats (Diverse 12-lead clinical data)
* **Preprocessing:** NeuroKit2 pipeline with **187-sample fixed window** segmentation

### ðŸ§  Model Architectures
**1. Deep CNN (Robust Classifier)**
* **Structure:** 2-Layer 1D-Convolutional Network with MaxPooling and Dropout (0.5)
* **Kernels:** 32 & 64 filters (Kernel Size=5) optimized for morphological feature extraction
* **Loss Function:** **Focal Loss** implemented to counter class imbalance

**2. Spiking Neural Network (Neuromorphic)**
* **Neuron Model:** Leaky Integrate-and-Fire (LIF) with surrogate gradient descent
* **Simulation:** **50 Time Steps** per inference window:
* **Decay Rate:** $\beta = 0.95$ (Optimized for membrane potential retention)

---

## ðŸ— Architecture

The system follows a modular pipeline from raw signal ingestion to edge deployment.

```mermaid
graph LR
    A[Raw ECG Data] --> B(Preprocessing & Segmentation)
    B --> C{Unified Dataset Creation}
    C --> D[Training Loop]
    D --> E[Model Zoo]
    E --> F[Deployment Dashboard]

    subgraph Models
        E1[Standalone CNN]
        E2[SNN Neuromorphic]
        E3[CNN+LSTM]
    end

    E --> E1
    E --> E2
    E --> E3
````

-----

## âš™ï¸ Installation

To ensure environment stability, requirements are split into two categories.

### 1\. Clone the Repository

```bash
git clone https://github.com/Vishwanath-06/PulsePod.git
cd PulsePod
git lfs install
git lfs pull
```

### 2\. Set up the Environment

**Option A: For Standard CNN Models (Recommended)**
Use this for the main Dashboard and standard Deep Learning models.

```bash
# Create virtual environment
python -m venv venv_cnn
source venv_cnn/bin/activate  # or venv_cnn\Scripts\activate on Windows

# Install dependencies
pip install -r cnn_requirements.txt
```

**Option B: For Neuromorphic SNN Experiments**
Use this specifically for running Spiking Neural Networks.

```bash
# Create virtual environment
python -m venv venv_snn
source venv_snn/bin/activate  # or venv_snn\Scripts\activate on Windows

# Install dependencies
pip install -r snn_requirements.txt
```

-----

## ðŸš€ Usage

### 1\. Launch the Dashboard

Visualize the inference stream in a web interface.

```bash
# Ensure venv_cnn is active
streamlit run app.py
```

### 2\. Data Preprocessing (Optional)

The test data is already provided in `.npy` format in the `data/` folder. If you wish to regenerate the unified test set from raw sources:

```bash
python data/create_unified_test_set.py
```

-----

## ðŸ“Š Performance & Results

We evaluated our models on a held-out, multi-domain test set (Unified MIT-BIH + PTB-XL, **61,126 samples**) to ensure true robustness.

| Model Architecture | Accuracy | Precision (Abnormal) | Recall (Abnormal) | F1-Score | Use Case |
| :--- | :---: | :---: | :---: | :---: | :--- |
| **Robust CNN** | **87%** | **0.89** | 0.86 | **0.88** | Best Overall Balance |
| **Spiking NN (SNN)** | 85% | 0.85 | **0.87** | 0.86 | Ultra-Low Power / High Recall |
| **CNN + LSTM** | 75%* | 0.95 | 0.58 | 0.72 | Precision / Specificity |

*> **Note:** While CNN-LSTM performed well on clean data, the standalone CNN demonstrated superior generalization on the heterogeneous PTB-XL test set (82% vs 75%).*

### ðŸ“ˆ Detailed Evaluation
The confusion matrices below demonstrate the Robust CNN's ability to minimize False Negatives (critical for healthcare), while the metrics comparison highlights the SNN's competitive performance despite being energy-efficient.

**Confusion Matrices (Generalization Test)**
![Confusion Matrices](assets/results.png)

**Model-wise Metrics Comparison**
![Metrics Comparison](assets/metrics.png)
-----

## ðŸ“‚ Project Structure

```text
PulsePod/
â”œâ”€â”€ data/                           # Processed .npy datasets & Scripts
â”‚   â”œâ”€â”€ mit_bih/
â”‚   â”œâ”€â”€ ptb_xl/
â”‚   â”œâ”€â”€ unified_test_set/
â”‚   â””â”€â”€ create_unified_test_set.py  # Script to merge datasets
â”œâ”€â”€ models/                         # Pre-trained PyTorch models
â”‚   â”œâ”€â”€ final_robust_cnn.pt
â”‚   â”œâ”€â”€ final_robust_cnn_focal_loss.pt
â”‚   â”œâ”€â”€ final_robust_cnn_lstm.pt
â”‚   â””â”€â”€ final_robust_snn.pt
â”œâ”€â”€ app.py                          # Main Streamlit Dashboard
â”œâ”€â”€ cnn_requirements.txt            # Standard dependencies
â”œâ”€â”€ snn_requirements.txt            # SNN dependencies
â””â”€â”€ readme.md
```

-----

## ðŸ”® Future Scope

  * **Hardware Porting:** Deploy SNN models to Intel Loihi or Neuromorphic chips.
  * **Multi-Class:** Extend detection to specific arrhythmias (AFib, PVC, LBBB).
  * **Federated Learning:** Implement privacy-preserving patient data training.

<div align="center">Built with ðŸ’™ by Vishwanath.T</div>
